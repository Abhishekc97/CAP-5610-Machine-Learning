{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, CategoricalNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from IPython.display import Image\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'Home': [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0],\n",
    "             'AP25': [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
    "             'NBC':   [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0],\n",
    "             'ESPN':  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "             'FOX':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "             'ABC':   [0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
    "             'CBS':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "             'Win':   [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
    "        }\n",
    "\n",
    "test_data = {'Home': [1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
    "            'AP25':  [0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
    "              'NBC': [1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
    "             'ESPN': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              'FOX': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              'ABC': [0, 0, 0, 0, 0, 1, 0, 0, 0 ,1, 0, 1],\n",
    "              'CBS': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              'Win': [1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=train_data)\n",
    "df_test = pd.DataFrame(data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 12 points : 3\n",
      "y_pred: [1 1 1 0 1 0 1 1 1 0 1 0]\n",
      "Accuracy: 0.75\n",
      "Precision, Recall, F1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.67      0.57         3\n",
      "           1       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.69      0.72      0.70        12\n",
      "weighted avg       0.78      0.75      0.76        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['Home', 'AP25', 'NBC', 'ESPN', 'FOX', 'ABC', 'CBS']\n",
    "\n",
    "x_train = df_train[feature_cols]\n",
    "y_train = df_train.Win\n",
    "\n",
    "x_test = df_test[feature_cols]\n",
    "y_test = df_test.Win\n",
    "\n",
    "# gnb = GaussianNB()\n",
    "# mnb = MultinomialNB()\n",
    "cnb = CategoricalNB ()\n",
    "\n",
    "y_pred = cnb.fit(x_train, y_train).predict(x_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (x_test.shape[0], (y_test != y_pred).sum()))\n",
    "\n",
    "print('y_pred:', y_pred)\n",
    "print('Accuracy:',metrics.accuracy_score(y_test,y_pred))\n",
    "print('Precision, Recall, F1')\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5  tree is going to be built...\n",
      "Accuracy:  79.16666666666667 % on  24  instances\n",
      "finished in  0.6690230369567871  seconds\n",
      "\n",
      "\n",
      "Predicted output using C4.5:  ['Win', 'Win', 'Win', 'None', 'Win', 'Win', 'Win', 'Win', 'Win', 'Lose', 'Win', 'Lose']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Lose       1.00      0.67      0.80         3\n",
      "        None       0.00      0.00      0.00         0\n",
      "         Win       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.83        12\n",
      "   macro avg       0.63      0.52      0.56        12\n",
      "weighted avg       0.92      0.83      0.87        12\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhishek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from chefboost import Chefboost as chef\n",
    "\n",
    "X_train = pd.read_csv(\"train.csv\")\n",
    "X_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_train_data = X_train.iloc[:, 3:]\n",
    "X_test_data = X_test.iloc[:, 3:6]\n",
    "\n",
    "Y_test = X_test.iloc[:, 6:]\n",
    "\n",
    "config = {'algorithm': 'C4.5'}\n",
    "\n",
    "model = chef.fit(X_train_data, config)\n",
    "y_pred_C45 = list()\n",
    "for index, instance in X_test_data.iterrows():\n",
    "    prediction = chef.predict(model, instance)\n",
    "    y_pred_C45.append(str(prediction))\n",
    "print(\"\\n\")\n",
    "print(\"Predicted output using C4.5: \", y_pred_C45)\n",
    "# print accuracy, precision, recall, and f1 score\n",
    "print(metrics.classification_report(Y_test, y_pred_C45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3_y_pred: [1 0 1 1 1 1 0 1 1 0 1 0]\n",
      "Precision, Recall, F1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86         3\n",
      "           1       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.92        12\n",
      "   macro avg       0.88      0.94      0.90        12\n",
      "weighted avg       0.94      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf2 = clf2.fit(x_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(x_test)\n",
    "\n",
    "print('ID3_y_pred:', y_pred2)\n",
    "\n",
    "# print('Accuracy:',metrics.accuracy_score(y_test,y_pred2))\n",
    "print('Precision, Recall, F1')\n",
    "print(metrics.classification_report(y_test,y_pred2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
